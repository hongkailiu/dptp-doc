# My TODOs to Alleviate Panic

It would be useful for me to have a DPTP devops handbook with those chapters. We can start to make the list (of tools/logs below) longer if it is cover for some accident.

## CI-Cluster architecture

* cloud provider, cluster-size, instance type, OCP roles.
* Doc on the whole OPC cluster installation and configuration procedure: For OCP 3 ... the playbook to run and the inventory file.
* deployed OCP components/plugins/configuration and its functionalities
* deployed prow-components/plugins/configuration and its functionalities.
* ci-tools/ci-operator: how it works and what pods it creates and what is running inside each pod? Any prowjobs in our cluster that are not under the hook of ci-operator. How ci-operator interacts with test-infra (prow components).

I started already [collecting information](../architecture.md) piece by piece for the last 2 items. But I feel it is far away from being adequate.

## Where we get the feeling that cluster is not working well

* slack channel: #forum-testplatform and #ops-testplatform (alerts from alertmanager), and #4-dev-triage
* failures on #build-cop-alerts: all jobs start to fail.
* slack: message mentioning @testplatform-team (that is for us). People start to shout out about failing jobs.

I am sometimes (if not mostly) not that responsive to slack msgs with excuses

* I know too little about DPTP to be helpful
* I am too busy with understand the stuff from current Jira card (what this line of code means, why it does not work as expected)

## Tools for debugging issues of our CI-cluster

* logs: category/way to grepping/contents
    * pod logs: oc command
    * prowjob logs: deck UI
    * journal logs (eg, `atomic-openshift-node`): ssh to to node?
    * output from specific cli tools (such as `ip` or `nstat` today): This would be more difficult for OCP4+ because it is core os and hard to establish the ssh connection.
    * google stackdriver logging
    * sentry

For the [postmortem report](https://docs.google.com/document/d/1vHKchB-Vt9ghg_A35k6nFueuAWi1pSbG2lh6wKOWWSA/edit#), the logs (at least i feel like so) are listed, but I have no idea where you get them (except the ones with the links).

I get the impression some of them are from `stackdriver` but I need more doc-reading/practicing on it.

* metrics: centrol place to do a quick search (ctrl+f).
    * openshift-monitoring
    * prow-monitoring

I would start to update [prow/metrics](https://github.com/kubernetes/test-infra/tree/master/prow/metrics).

For openshift monitoring, we can start to make this table:

| Type      	| Metric                    	| Labels                	| Description                                               	|
|-----------	|---------------------------	|-----------------------	|-----------------------------------------------------------	|
|      	| `container_cpu_usage_seconds_total`               	|      	|  	|

* Commands for trouble shooting

I am [collecting those](../cmd.md) too.
I feel more comfortable if I can search/copy/paster.

BTW, `oc adm policy add-cluster-role-to-user cluster-monitoring-view danwinship` ... I think it is persistent already.


## Doc on what we learn from each ACCIDENT

* key symptoms/logs 
* where to find it
* what it means ... Dan identified it is resourse starving issue.
* if the knowledge is not from our team, then list the team name(s)
* key step to find the root cause
* key step to remove the root cause and remove the symptoms

For this accident today, I have so many dots to connect.

why did you switch from searching PR in the installer to considering CPU metrics for container? why pod metrics is not enough/helping?

You listed the command for retag latest with the previous images. How did get the sha for docker image? Yes ... you told me before how to find the commit the image was build with.
